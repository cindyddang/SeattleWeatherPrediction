# -*- coding: utf-8 -*-
"""LSTM_Seattles.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bKA9FUS6aSe_k9c9oxPb18OEXvGjRnIa
"""

import warnings
warnings.filterwarnings('ignore')

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler, LabelEncoder
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from tensorflow.keras.utils import to_categorical

# Load data
df = pd.read_csv('/content/seattle-weather.csv', index_col='date')
df = df.sort_values(by=['date'])
df.head()

# Encode categorical 'weather' column
label_encoder = LabelEncoder()
df['weather_encoded'] = label_encoder.fit_transform(df['weather'])
weather_categories = label_encoder.classes_

# Normalize numerical columns
scaler = MinMaxScaler()
numerical_features = ['precipitation', 'temp_max', 'temp_min', 'wind']
df[numerical_features] = scaler.fit_transform(df[numerical_features])

from sklearn.model_selection import train_test_split

# Prepare input sequences
sequence_length = 3
features = numerical_features + ['weather_encoded']
sequences = []
targets = []

for i in range(len(df) - sequence_length):
    seq = df[features].iloc[i:i + sequence_length].values
    target = df['weather_encoded'].iloc[i + sequence_length]
    sequences.append(seq)
    targets.append(target)

X = np.array(sequences)
y = to_categorical(np.array(targets))  # One-hot encode targets

# Split into training and test sets (small dataset, so all for training here)
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)

# Build LSTM model
model = Sequential([
    LSTM(50, input_shape=(sequence_length, len(features))),
    # Dense(50, activation='relu'),
    Dense(len(weather_categories), activation='softmax')
])

# model = Sequential()
# model.add(LSTM(64,input_shape=(sequence_length, len(features))))
# model.add(Dense(32,"relu"))
# model.add(Dropout(0.2))
# model.add(Dense(16,"relu"))
# model.add(Dense(len(weather_categories), activation='softmax'))

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Train model
history = model.fit(
    X_train, y_train,
    validation_data=(X_val, y_val),
    epochs=20,
    batch_size=16,
    verbose=1
)

# Evaluate model
loss, accuracy = model.evaluate(X_val, y_val, verbose=1)
print(f"Validation Accuracy: {accuracy:.2f}")

# Predict for the entire validation set
predictions = model.predict(X_val)

# Decode predictions to weather labels
predicted_weather_indices = np.argmax(predictions, axis=1)
predicted_weather_labels = label_encoder.inverse_transform(predicted_weather_indices)

# Decode true labels to weather labels for comparison
true_weather_indices = np.argmax(y_val, axis=1)
true_weather_labels = label_encoder.inverse_transform(true_weather_indices)

# Print predictions and true values
for i in range(10):
    print(f"Sample {i+1}: Predicted = {predicted_weather_labels[i]}, True = {true_weather_labels[i]}")

from sklearn.metrics import accuracy_score, classification_report

accuracy = accuracy_score(true_weather_labels, predicted_weather_labels)
print(f"Validation Accuracy: {accuracy}")

# Print classification report
print("Classification Report:")
print(classification_report(true_weather_labels, predicted_weather_labels, target_names=label_encoder.classes_))

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

# Confusion Matrix
cm = confusion_matrix(true_weather_labels, predicted_weather_labels)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=label_encoder.classes_)
disp.plot(cmap=plt.cm.Blues)
plt.title("Confusion Matrix")
plt.show()